{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Kuhlman-Lab/PIPPack/blob/main/notebooks/PIPPack.ipynb)"
      ],
      "metadata": {
        "id": "qxlaw93Rsvpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook includes the ability to pack the side chains of a protein given its PDB code or an uploaded PDB file and resample the predicted side chains."
      ],
      "metadata": {
        "id": "9FieedNsNsVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Check Colab Settings**\n",
        "\n",
        "PIPPack does not require the use of a GPU, but predictions will be faster with a GPU. To check that GPU use is enabled:\n",
        "- Use the Colab settings bar above to navigate to `Runtime` -> `Change runtime type`\n",
        "- Make sure that `Runtime type` is set to `Python 3`\n",
        "- Make sure that `Hardware accelerator` is set to `GPU`\n",
        "- Click `Save` to confirm"
      ],
      "metadata": {
        "id": "F9kKVp-QNkCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# @title ## **Step 2: Set up PIPPack**\n",
        "# @markdown Import PIPPack and its dependencies to this session. This may take a minute or two.\n",
        "\n",
        "# @markdown You only need to do this once *per session*. To re-run PIPPack on a new protein, with a new sequence, or with another model, you can start on Step 3.\n",
        "\n",
        "# Cleaning out any remaining data\n",
        "!rm -rf /content/PIPPack\n",
        "\n",
        "# Making sure Colab can access the GitHub repo\n",
        "import os\n",
        "if not os.path.exists(\"/content/PIPPack\"):\n",
        "  ! git clone https://github.com/Kuhlman-Lab/PIPPack.git\n",
        "  %cd /content/PIPPack\n",
        "\n",
        "# Downloading various dependencies\n",
        "! pip install omegaconf lightning==2.0.1 biopython nglview hydra-core torch_geometric"
      ],
      "metadata": {
        "id": "i06A5VI142NT",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "#@title ## **Step 3: Input Data and Prediction Options**\n",
        "\n",
        "#@markdown ### **INPUT SETTINGS**\n",
        "\n",
        "# -------- Collecting Settings for PIPPack run --------- #\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "from urllib import request\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "\n",
        "def download_pdb(pdbcode, datadir, downloadurl=\"https://files.rcsb.org/download/\"):\n",
        "    \"\"\"\n",
        "    Downloads a PDB file from the Internet and saves it in a data directory.\n",
        "    :param pdbcode: The standard PDB ID e.g. '3ICB' or '3icb'\n",
        "    :param datadir: The directory where the downloaded file will be saved\n",
        "    :param downloadurl: The base PDB download URL, cf.\n",
        "        `https://www.rcsb.org/pages/download/http#structures` for details\n",
        "    :return: the full path to the downloaded PDB file or None if something went wrong\n",
        "    \"\"\"\n",
        "\n",
        "    pdbfn = pdbcode + \".pdb\"\n",
        "    url = downloadurl + pdbfn\n",
        "    outfnm = os.path.join(datadir, pdbfn)\n",
        "    try:\n",
        "        request.urlretrieve(url, outfnm)\n",
        "        return outfnm\n",
        "    except Exception as err:\n",
        "        print(str(err), file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "#@markdown You may either specify a PDB code to fetch or upload a custom PDB file.\n",
        "\n",
        "#@markdown PDB code (e.g., 1PGA):\n",
        "pdb = \"1PGA\" # @param {type: \"string\"}\n",
        "\n",
        "#@markdown Upload custom PDB?\n",
        "custom_pdb = True # @param {type: \"boolean\"}\n",
        "#@markdown If enabled, a `Choose files` button will appear once this cell is run.\n",
        "\n",
        "if custom_pdb:\n",
        "  print('PDB Upload:')\n",
        "  uploaded_pdb = files.upload()\n",
        "  for fn in uploaded_pdb.keys():\n",
        "    pdb = os.path.basename(fn)\n",
        "    if not pdb.endswith('.pdb'):\n",
        "      raise ValueError(f\"Uploaded file {pdb} does not end in '.pdb'. Please check and rename file as needed.\")\n",
        "    os.rename(fn, os.path.join(\"/content/\", pdb))\n",
        "    pdb_file = os.path.join(\"/content/\", pdb)\n",
        "else:\n",
        "  try:\n",
        "    fn = download_pdb(pdb, \"/content/\")\n",
        "    if fn is None:\n",
        "      raise ValueError(\"Failed to fetch PDB from RSCB. Please double-check PDB code and try again.\")\n",
        "    else:\n",
        "      pdb_file = fn\n",
        "  except HTTPError:\n",
        "    raise HTTPError(f\"No protein with code {pdb} exists in RSCB PDB. Please double-check PDB code and try again.\")\n",
        "\n",
        "#@markdown Chain(s) of interest (e.g., A or A,B):\n",
        "chain = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown If left blank, PIPPack will pack all chains in the PDB. To pack just a subset of chains, input the chain ids as a comma-separated list (e.g., A,B)\n",
        "\n",
        "#@markdown Sequence to pack:\n",
        "sequence = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown If left blank, the native sequence in the PDB will be repacked. If specifying multiple chains, separate the chain sequences with a '/'. The length of the sequence(s) MUST match the length of the chain(s) in the PDB file.\n",
        "\n",
        "##custom_fasta = False # @param {type: \"boolean\"}\n",
        "###@markdown If enabled, a `Choose files` button will appear once this cell is run. PIPPack will pack all sequences found in the fasta file as long as their length matches the length of the structure in the PDB. If specifying multiple chains, separate the chain sequences with a '/'.\n",
        "\n",
        "## @markdown Generate ProteinMPNN sequences:\n",
        "#n_proteinmpnn_seqs = 0 # @param {type: \"integer\"}\n",
        "\n",
        "##@markdown Sequence sampling temperature:\n",
        "##seq_temperature = 0.2 # @param {type:\"number\"}\n",
        "\n",
        "## @markdown Note the ProteinMPNN model used in this notebook is the v_48_010 model from the official repo: https://github.com/dauparas/ProteinMPNN.\n",
        "\n",
        "if custom_fasta:\n",
        "  print('Fasta Upload:')\n",
        "  uploaded_fasta = files.upload()\n",
        "  for fn in uploaded_fasta.keys():\n",
        "    fasta = os.path.basename(fn)\n",
        "    if not fasta.endswith('.fasta'):\n",
        "      raise ValueError(f\"Uploaded file {fasta} does not end in '.fasta'. Please check and rename file as needed.\")\n",
        "    os.rename(fn, os.path.join(\"/content/\", fasta))\n",
        "    fasta_file = os.path.join(\"/content/\", fasta)\n",
        "\n",
        "    with open(fasta_file, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "    seqs = [line.strip() for line in lines if line[0] != \">\" and line]\n",
        "else:\n",
        " seqs = [sequence]\n",
        "seqs = [seq.split('/') for seq in seqs]\n",
        "\n",
        "convert_mse_to_met = True # @param {type: \"boolean\"}\n",
        "#@markdown If enabled, any MSE residue will be parsed as MET. If disabled, MSE residues are ignored.\n",
        "\n",
        "\n",
        "#@markdown ### **MODEL SETTINGS**\n",
        "\n",
        "#@markdown Model to use:\n",
        "model = \"PIPPack (ensemble)\" # @param [\"PIPPack (model 1)\", \"PIPPack (model 2)\", \"PIPPack (model 3)\", \"PIPPack (ensemble)\"]\n",
        "\n",
        "#@markdown Side chain sampling temperature:\n",
        "chi_temperature = 0.0 # @param {type:\"number\"}\n",
        "# @markdown Higher temperature results in more diversity of conformations, but also conformations that the model is less confident about. Use T=0.0 for best results.\n",
        "\n",
        "# @markdown Number of recycles:\n",
        "recycles = 3 # @param {type: \"integer\"}\n",
        "\n",
        "# @markdown Random seed:\n",
        "use_seed = True # @param {type: \"boolean\"}\n",
        "seed = 3445 # @param {type: \"integer\"}\n",
        "# @markdown Enabling seed by checking \"use_seed\" will use the \"seed\" value for random number generation. Disabling will result in a random seed.\n",
        "\n",
        "#@markdown Resampling Arguments:\n",
        "use_resampling = True #@param {type:\"boolean\"}\n",
        "sample_temp = 0.1 # @param {type:\"number\"}\n",
        "clash_overlap_tolerance = 0.4 # @param {type:\"number\"}\n",
        "pro_tolerance_factor = 12 # @param {type:\"integer\"}\n",
        "max_iters = 50 # @param {type:\"integer\"}\n",
        "metropolis_temp = 0.000005 # @param {type:\"number\"}\n",
        "#@markdown Note these arguments pertain to the resampling procedure that is applied after PIPPack prediction to reduce the amount of clashing residues. These defaults are sensible ones used in the results of the paper. Feel free to experiment with other settings, and share if you find anything interesting!\n",
        "\n",
        "resample_args = {\n",
        "    \"sample_temp\": sample_temp,\n",
        "    \"clash_overlap_tolerance\": clash_overlap_tolerance,\n",
        "    \"pro_tolerance_factor\": pro_tolerance_factor,\n",
        "    \"max_iters\": max_iters,\n",
        "    \"metropolis_temp\": metropolis_temp,\n",
        "}"
      ],
      "metadata": {
        "id": "UhVRKrjpJiST",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## **Step 4: Run PIPPack**\n",
        "\n",
        "# ---------- Model Name Parsing ---------- #\n",
        "import pickle\n",
        "\n",
        "if model == \"PIPPack (model 1)\":\n",
        "  model_names = [\"pippack_model_1\"]\n",
        "elif model == \"PIPPack (model 2)\":\n",
        "  model_names = [\"pippack_model_2\"]\n",
        "elif model == \"PIPPack (model 3)\":\n",
        "  model_names = [\"pippack_model_3\"]\n",
        "else:\n",
        "  model_names = [\"pippack_model_1\", \"pippack_model_2\", \"pippack_model_3\"]\n",
        "\n",
        "# Parse one of the configs to get n_chi_bins\n",
        "with open(f'/content/PIPPack/model_weights/{model_names[0]}_config.pickle', 'rb') as f:\n",
        "  cfg = pickle.load(f)\n",
        "n_chi_bins = cfg.model.n_chi_bins\n",
        "\n",
        "\n",
        "# ---------- PDB Parsing and Dataset Creation ---------- #\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/PIPPack')\n",
        "\n",
        "from data.protein import from_pdb_file\n",
        "from data.top2018_dataset import transform_structure, collate_fn\n",
        "from inference import replace_protein_sequence\n",
        "\n",
        "# Load the appropriate chains from the PDB file\n",
        "chains = chain.strip().split(',')\n",
        "if chains == ['']:\n",
        "  chains = None\n",
        "protein = vars(from_pdb_file(pdb_file, chain_id=chains, mse_to_met=convert_mse_to_met))\n",
        "\n",
        "# Generate or swap sequence, if necessary\n",
        "if n_proteinmpnn_seqs > 0:\n",
        "  import torch\n",
        "  from proteinmpnn.model_utils import ProteinMPNN\n",
        "  from utils.train_utils import load_checkpoint\n",
        "  import data.residue_constants as rc\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  # Don't reload sequence design model if rerunning cell\n",
        "  if 'seq_model' not in locals():\n",
        "    n_gen_seqs = n_proteinmpnn_seqs\n",
        "    seq_model_ckpt = '/content/proteinmpnn_ckpt.pt'\n",
        "    request.urlretrieve('https://github.com/dauparas/ProteinMPNN/raw/main/vanilla_model_weights/v_48_010.pt', seq_model_ckpt)\n",
        "    seq_model = ProteinMPNN(k_neighbors=48, augment_eps=0.0, use_ipmp=False).to(device)\n",
        "    seq_model_ckpt = torch.load(seq_model_ckpt, map_location='cpu')\n",
        "    seq_model.load_state_dict(seq_model_ckpt['model_state_dict'])\n",
        "\n",
        "  # Reshape protein for sequence design\n",
        "  seqs = []\n",
        "  batch = transform_structure(protein)\n",
        "  batch = collate_fn([batch]).to(device)\n",
        "  for i in range(n_gen_seqs):\n",
        "    randn = torch.randn(batch.S.shape, device=device)\n",
        "    sample_out = seq_model.sample(batch.X, randn, batch.S, torch.ones_like(batch.S), torch.zeros_like(batch.S), batch.residue_index, batch.residue_mask, temperature=seq_temperature)\n",
        "    seq = sample_out['S'].squeeze(0)\n",
        "    seqs.append([''.join([rc.restypes_with_x[s] for s in seq])])\n",
        "    print(f'Generated sequence with ProteinMPNN: {seqs[-1]}')\n",
        "\n",
        "if seqs != [['']]:\n",
        "  # Replace any Xs that were generated\n",
        "  seqs = [[s.replace('X', 'G') for s in seq] for seq in seqs]\n",
        "  proteins = replace_protein_sequence(protein, os.path.basename(pdb_file)[:-4], seqs)\n",
        "else:\n",
        "  proteins = [(os.path.basename(pdb_file)[:-4], protein)]\n",
        "\n",
        "# Transform proteins\n",
        "proteins = [(protein[0], transform_structure(protein[1], n_chi_bins, sc_d_mask_from_seq=True)) for protein in proteins]\n",
        "\n",
        "\n",
        "# ---------- Model Loading ------------- #\n",
        "import hydra\n",
        "import torch\n",
        "from utils.train_utils import load_checkpoint\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Don't reload model if rerunning cell\n",
        "if 'models' not in locals():\n",
        "  models = []\n",
        "  for model_name in model_names:\n",
        "    cfg_file = f'/content/PIPPack/model_weights/{model_name}_config.pickle'\n",
        "    ckpt_file = f'/content/PIPPack/model_weights/{model_name}_ckpt.pt'\n",
        "\n",
        "    with open(cfg_file, 'rb') as f:\n",
        "      cfg = pickle.load(f)\n",
        "\n",
        "    m = hydra.utils.instantiate(cfg.model).to(device)\n",
        "    load_checkpoint(ckpt_file, m)\n",
        "\n",
        "    models.append(m)\n",
        "\n",
        "# ---------- Inference -------- #\n",
        "import time\n",
        "import lightning\n",
        "from inference import pdbs_from_prediction\n",
        "from ensembled_inference import sample_epoch\n",
        "from model.modules import get_atom14_coords\n",
        "from model.resampling import resample_loop\n",
        "import warnings\n",
        "\n",
        "# Seed for predictions\n",
        "if not use_seed:\n",
        "  seed = None\n",
        "# Clear the global seed set by PL\n",
        "if \"PL_GLOBAL_SEED\" in os.environ:\n",
        "  os.environ.pop(\"PL_GLOBAL_SEED\")\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter('ignore')\n",
        "  _ = lightning.seed_everything(seed)\n",
        "\n",
        "predictions = {}\n",
        "for protein_item in proteins:\n",
        "  # Unpack batch\n",
        "  pdb_name = protein_item[0]\n",
        "  protein = protein_item[1]\n",
        "\n",
        "  # Collate the batch\n",
        "  batch = collate_fn([protein])\n",
        "\n",
        "  # Perform inference\n",
        "  t0 = time.time()\n",
        "  sample_results = sample_epoch(models, batch, chi_temperature, device, n_recycle=recycles)\n",
        "\n",
        "  # Perform resampling, if desired\n",
        "  if use_resampling:\n",
        "    for i in range(batch.S.shape[0]):\n",
        "      # Get the protein components.\n",
        "      temp_protein = {\n",
        "          \"S\": sample_results[\"S\"][i],\n",
        "          \"X\": sample_results[\"X\"][i],\n",
        "          \"X_mask\": sample_results[\"X_mask\"][i],\n",
        "          \"BB_D\": sample_results[\"BB_D\"][i],\n",
        "          \"residue_index\": sample_results[\"residue_index\"][i],\n",
        "          \"residue_mask\": sample_results[\"residue_mask\"][i],\n",
        "          \"chi_logits\": sample_results[\"chi_logits\"][i],\n",
        "          \"chi_bin_offset\": sample_results[\"chi_bin_offset\"][i] if \"chi_bin_offset\" in sample_results else None,\n",
        "      }\n",
        "      pred_xyz = sample_results[\"final_X\"][i]\n",
        "\n",
        "      # Perform resampling\n",
        "      resample_xyz, _ = resample_loop(temp_protein, pred_xyz, **resample_args)\n",
        "\n",
        "      # Update the coordinates\n",
        "      sample_results[\"final_X\"][i] = resample_xyz\n",
        "  print(f'Packed {\"and resampled \" if use_resampling else \"\"}{pdb_name} ({batch.S.numel()} residues) using {model} in {time.time() - t0:.3f} sec.')\n",
        "\n",
        "  # Store prediction and processed pdb string\n",
        "  pdb_str = pdbs_from_prediction(sample_results)[0]\n",
        "  predictions[pdb_name] = {'results': sample_results, 'pdb_str': pdb_str}\n"
      ],
      "metadata": {
        "id": "eCNE3sHwTDGw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Step 5: Visualize Packed Nanobody**\n",
        "!pip install py3Dmol > /dev/null\n",
        "import py3Dmol\n",
        "from pathlib import Path\n",
        "import math\n",
        "\n",
        "# Configuration parameters\n",
        "Output_pdb_name = 'design_15_model'  # @param {type:\"string\"}\n",
        "#hotspot_res = None  # @param {type:\"string\"}  # Inserisci i residui hotspot separati da virgola\n",
        "\n",
        "# Load PDB file\n",
        "pdb_file_path = f\"../{Output_pdb_name}.pdb\"\n",
        "pdb_content = Path(pdb_file_path).read_text()\n",
        "\n",
        "# Dizionario per mappare i codici degli amminoacidi da tre lettere a una lettera\n",
        "AA_THREE_TO_ONE = {\n",
        "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',\n",
        "    'GLN': 'Q', 'GLU': 'E', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
        "    'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',\n",
        "    'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'\n",
        "}\n",
        "\n",
        "# Parse interacting residues between chain H (nanobody) and chain T (target)\n",
        "atoms_H = []  # H chain (nanobody heavy chain)\n",
        "atoms_T = []  # T chain (target)\n",
        "sequences = {}  # Per memorizzare le sequenze delle catene\n",
        "\n",
        "for L in pdb_content.splitlines():\n",
        "    if L.startswith((\"ATOM  \",\"HETATM\")):\n",
        "        chain = L[21]\n",
        "        resi  = int(L[22:26])\n",
        "        resn  = L[17:20].strip()\n",
        "        x, y, z = map(float, (L[30:38], L[38:46], L[46:54]))\n",
        "\n",
        "        # Aggiungi alla sequenza\n",
        "        if chain not in sequences:\n",
        "            sequences[chain] = {}\n",
        "        if resi not in sequences[chain]:\n",
        "            sequences[chain][resi] = resn\n",
        "\n",
        "        if chain == 'H':  # Nanobody heavy chain\n",
        "            atoms_H.append((resi, resn, chain, (x, y, z)))\n",
        "        elif chain == 'T':  # Target chain\n",
        "            atoms_T.append((resi, resn, chain, (x, y, z)))\n",
        "\n",
        "# Stampa le sequenze primarie\n",
        "print(\"ðŸ”µ Primary Sequences:\")\n",
        "for chain in sorted(sequences.keys()):\n",
        "    print(f\"Chain {chain}:\")\n",
        "    residues = sorted(sequences[chain].items())\n",
        "    seq = \"\"\n",
        "    for resi, resn in residues:\n",
        "        # Converti da codice a tre lettere a una lettera\n",
        "        one_letter = AA_THREE_TO_ONE.get(resn, 'X')\n",
        "        seq += one_letter\n",
        "\n",
        "    # Stampa la sequenza formattata (max 80 caratteri per riga)\n",
        "    for i in range(0, len(seq), 80):\n",
        "        print(f\"   {seq[i:i+80]}\")\n",
        "    print()\n",
        "\n",
        "# Find residues in chain H within 6Ã… of chain T\n",
        "interacting_residues = set()\n",
        "for resi_H, resn_H, chain_H, coords_H in atoms_H:\n",
        "    for resi_T, resn_T, chain_T, coords_T in atoms_T:\n",
        "        if math.dist(coords_H, coords_T) <= 6.0:\n",
        "            interacting_residues.add(resi_H)\n",
        "            break\n",
        "\n",
        "# Print interacting residues\n",
        "if interacting_residues:\n",
        "    print(\"ðŸŸ¡ Interacting residues on chain H (within 6Ã… of chain T):\")\n",
        "    # Get residue names for interacting residues\n",
        "    residue_names = {}\n",
        "    for resi, resn, chain, coords in atoms_H:\n",
        "        if resi in interacting_residues:\n",
        "            residue_names[resi] = resn\n",
        "\n",
        "    for resi in sorted(interacting_residues):\n",
        "        one_letter = AA_THREE_TO_ONE.get(residue_names[resi], 'X')\n",
        "        print(f\"  {one_letter}{resi} ({residue_names[resi]}{resi})\")\n",
        "else:\n",
        "    print(\"âš ï¸ No H-chain residues found within 6Ã… of chain T\")\n",
        "\n",
        "# Create visualization\n",
        "view = py3Dmol.view(width=800, height=600)\n",
        "view.addModel(pdb_content, 'pdb')\n",
        "\n",
        "# Style the visualization\n",
        "view.setStyle({'chain':['H']}, {'cartoon': {'color': 'steelblue'}})  # Heavy chain\n",
        "view.setStyle({'chain':['L']}, {'cartoon': {'color': 'forestgreen'}})  # Light chain\n",
        "view.addSurface(py3Dmol.VDW, {'color': 'lightgrey', 'opacity': 0.75}, {'chain': 'T'})  # Target chain\n",
        "\n",
        "# Add hotspot residues\n",
        "if hotspot_res:\n",
        "    hotspot_residues = [int(\"\".join(filter(str.isdigit, r))) for r in hotspot_res.split(',')]\n",
        "    view.addStyle({'chain':'T','resi': hotspot_residues},  # Target chain\n",
        "                  {'sphere': {'color': 'red', 'radius': 1.5}})\n",
        "\n",
        "# Highlight entire interacting residues on chain H (not just atoms within threshold)\n",
        "if interacting_residues:\n",
        "    view.addStyle({'chain': 'H', 'resi': list(interacting_residues)},\n",
        "                  {'stick': {'color': 'yellow'}})\n",
        "\n",
        "view.zoomTo()\n",
        "view.show()\n",
        "\n",
        "# Print legend\n",
        "print(\"\\nLegend:\")\n",
        "print(\"ðŸŸ¦ Antibody (chain H, heavy chain) - Steel blue\")\n",
        "print(\"ðŸŸ© Antibody (chain L, light chain) - Forest green\")\n",
        "print(\"â¬œ Target (chain T) - Light grey surface\")\n",
        "print(\"ðŸ”´ Epitope Hotspots - Red spheres\")\n",
        "print(\"ðŸŸ¡ Interacting Residues (entire residue) - Yellow sticks\")"
      ],
      "metadata": {
        "id": "j_F8vVo4HWgI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Step 6: Save Predictions**\n",
        "\n",
        "# ---------- Save the packed protein ---------- #\n",
        "# @markdown You can save the packed proteins using the `pdb_name`. That is, if you saw \"Packed <u>1PGA</u> (56 residues) using PIPPack (ensemble) in  0.856 sec.\" as an output from Step 4, then `pdb_name='1PGA'`, as indicated by the underline.\n",
        "\n",
        "# @markdown The output file will have the name: \"{pdb_name}_{model_name}.pdb\" and can be accessed by clicking the folder icon on the left.\n",
        "\n",
        "\n",
        "# @markdown ### **Individual Download**\n",
        "# Get the input PDB name for output file naming\n",
        "input_pdb_name = os.path.basename(pdb_file).replace('.pdb', '')\n",
        "pdb_name = input_pdb_name # @param {type:\"string\"}\n",
        "# @markdown Do not be afraid if running this cell results in a `ValueError`. Read the message as it will explain what the valid options for `pdb_name` are.\n",
        "\n",
        "# @markdown ### **Download all**\n",
        "# @markdown Enable this option and run this cell to download all of the predictions.\n",
        "\n",
        "download_all = True # @param {type: \"boolean\"}\n",
        "\n",
        "if not download_all and pdb_name not in predictions:\n",
        "  raise ValueError(f\"pdb_name not a valid option. Try one of {list(predictions.keys())}.\")\n",
        "else:\n",
        "  output_files = [pdb_name]\n",
        "\n",
        "for pdb in output_files:\n",
        "  with open(f\"/content/{pdb}_{model.replace('(', '').replace(')', '').replace(' ', '_').lower()}.pdb\", 'w') as f:\n",
        "    f.write(predictions[pdb]['pdb_str'])"
      ],
      "metadata": {
        "id": "KxcK2vDyUF4L",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **License**\n",
        "The source code for PIPPack, including licensing information, can be found [here](https://github.com/Kuhlman-Lab/PIPPack).\n",
        "\n",
        "### **Citation Information**\n",
        "\n",
        "If you use PIPPack in your own research, please cite [this preprint](https://www.biorxiv.org/content/10.1101/2023.08.03.551328):\n",
        "\n",
        "Randolph NZ, Kuhlman B. Invariant point message passing for protein side chain packing. BioRxiv. August 3, 2023. doi:10.1101/2023.08.03.551328"
      ],
      "metadata": {
        "id": "xm6eoGgIU23o"
      }
    }
  ]
}
